{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ***0. Data Loading***"],"metadata":{"id":"Q1wcnjQODYQ4"}},{"cell_type":"markdown","source":["Import NB15 dataset on your Google Drive then run this cell\n","\n","To-do:\n","- [x] Verify pandas.DataFrame = polars.DataFrame with no floating value difference\n","- [x] Verify polars is faster than pandas in reading csv, around 70-110ms difference"],"metadata":{"id":"Q3VVMd4Fj301"}},{"cell_type":"code","source":["############################################################\n","#put your code for reading the csv data here\n","############################################################\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/\n","\n","import polars as pl\n","def polar_read_csv(csv_train, csv_val, csv_test):\n","    \"\"\"\n","    Args:\n","        csv_train (str): name of train set csv file\n","        csv_val (str): name of val set csv file\n","        csv_test (str): name of test set csv file\n","\n","    Output:\n","        read train, val, test sets in DataFrame format\n","    \"\"\"\n","    df_train = pl.read_csv(csv_train)\n","    df_val = pl.read_csv(csv_val)\n","    df_test = pl.read_csv(csv_test)\n","\n","    return df_train, df_val, df_test\n","\n","polar_read_csv(\"UNSWNB15_training_coursework.csv\", \"UNSWNB15_testing1_coursework.csv\", \"UNSWNB15_testing2_coursework_no_label.csv\")"],"metadata":{"id":"n6MJyx0bDlFa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744354831477,"user_tz":-60,"elapsed":24454,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}},"outputId":"c8c27307-b3c6-4445-aca8-cc29e4c5c9b9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["(shape: (20_000, 44)\n"," ┌───────┬──────────┬───────┬─────────┬───┬────────────┬────────────┬─────────────────┬───────┐\n"," │ id    ┆ dur      ┆ proto ┆ service ┆ … ┆ ct_src_ltm ┆ ct_srv_dst ┆ is_sm_ips_ports ┆ label │\n"," │ ---   ┆ ---      ┆ ---   ┆ ---     ┆   ┆ ---        ┆ ---        ┆ ---             ┆ ---   │\n"," │ i64   ┆ f64      ┆ str   ┆ str     ┆   ┆ i64        ┆ i64        ┆ i64             ┆ i64   │\n"," ╞═══════╪══════════╪═══════╪═════════╪═══╪════════════╪════════════╪═════════════════╪═══════╡\n"," │ 1     ┆ 0.000003 ┆ unas  ┆ -       ┆ … ┆ 8          ┆ 11         ┆ 0               ┆ 1     │\n"," │ 2     ┆ 0.885807 ┆ tcp   ┆ ftp     ┆ … ┆ 5          ┆ 1          ┆ 0               ┆ 0     │\n"," │ 3     ┆ 0.538781 ┆ tcp   ┆ http    ┆ … ┆ 2          ┆ 6          ┆ 0               ┆ 0     │\n"," │ 4     ┆ 0.000008 ┆ udp   ┆ dns     ┆ … ┆ 27         ┆ 34         ┆ 0               ┆ 1     │\n"," │ 5     ┆ 0.448734 ┆ tcp   ┆ ftp     ┆ … ┆ 1          ┆ 1          ┆ 0               ┆ 1     │\n"," │ …     ┆ …        ┆ …     ┆ …       ┆ … ┆ …          ┆ …          ┆ …               ┆ …     │\n"," │ 19996 ┆ 0.000008 ┆ sctp  ┆ -       ┆ … ┆ 2          ┆ 5          ┆ 0               ┆ 1     │\n"," │ 19997 ┆ 0.789808 ┆ tcp   ┆ http    ┆ … ┆ 2          ┆ 1          ┆ 0               ┆ 1     │\n"," │ 19998 ┆ 0.539269 ┆ tcp   ┆ http    ┆ … ┆ 6          ┆ 2          ┆ 0               ┆ 1     │\n"," │ 19999 ┆ 0.931055 ┆ tcp   ┆ -       ┆ … ┆ 2          ┆ 7          ┆ 0               ┆ 0     │\n"," │ 20000 ┆ 2.947155 ┆ tcp   ┆ -       ┆ … ┆ 1          ┆ 1          ┆ 0               ┆ 0     │\n"," └───────┴──────────┴───────┴─────────┴───┴────────────┴────────────┴─────────────────┴───────┘,\n"," shape: (4_000, 44)\n"," ┌──────┬──────────┬───────┬─────────┬───┬────────────┬────────────┬─────────────────┬───────┐\n"," │ id   ┆ dur      ┆ proto ┆ service ┆ … ┆ ct_src_ltm ┆ ct_srv_dst ┆ is_sm_ips_ports ┆ label │\n"," │ ---  ┆ ---      ┆ ---   ┆ ---     ┆   ┆ ---        ┆ ---        ┆ ---             ┆ ---   │\n"," │ i64  ┆ f64      ┆ str   ┆ str     ┆   ┆ i64        ┆ i64        ┆ i64             ┆ i64   │\n"," ╞══════╪══════════╪═══════╪═════════╪═══╪════════════╪════════════╪═════════════════╪═══════╡\n"," │ 1    ┆ 0.000009 ┆ sep   ┆ -       ┆ … ┆ 1          ┆ 6          ┆ 0               ┆ 1     │\n"," │ 2    ┆ 0.965595 ┆ tcp   ┆ ftp     ┆ … ┆ 2          ┆ 1          ┆ 0               ┆ 0     │\n"," │ 3    ┆ 0.000008 ┆ udp   ┆ dns     ┆ … ┆ 22         ┆ 35         ┆ 0               ┆ 1     │\n"," │ 4    ┆ 0.012175 ┆ tcp   ┆ -       ┆ … ┆ 1          ┆ 8          ┆ 0               ┆ 0     │\n"," │ 5    ┆ 0.000004 ┆ udp   ┆ dns     ┆ … ┆ 26         ┆ 26         ┆ 0               ┆ 1     │\n"," │ …    ┆ …        ┆ …     ┆ …       ┆ … ┆ …          ┆ …          ┆ …               ┆ …     │\n"," │ 3996 ┆ 0.689171 ┆ tcp   ┆ -       ┆ … ┆ 1          ┆ 6          ┆ 0               ┆ 0     │\n"," │ 3997 ┆ 1.091111 ┆ tcp   ┆ pop3    ┆ … ┆ 1          ┆ 1          ┆ 0               ┆ 1     │\n"," │ 3998 ┆ 0.017941 ┆ tcp   ┆ -       ┆ … ┆ 10         ┆ 8          ┆ 0               ┆ 0     │\n"," │ 3999 ┆ 0.000008 ┆ unas  ┆ -       ┆ … ┆ 4          ┆ 6          ┆ 0               ┆ 1     │\n"," │ 4000 ┆ 0.00095  ┆ udp   ┆ dns     ┆ … ┆ 2          ┆ 2          ┆ 0               ┆ 0     │\n"," └──────┴──────────┴───────┴─────────┴───┴────────────┴────────────┴─────────────────┴───────┘,\n"," shape: (25, 43)\n"," ┌─────┬──────────┬───────────┬─────────┬───┬──────────────┬────────────┬────────────┬──────────────┐\n"," │ id  ┆ dur      ┆ proto     ┆ service ┆ … ┆ ct_flw_http_ ┆ ct_src_ltm ┆ ct_srv_dst ┆ is_sm_ips_po │\n"," │ --- ┆ ---      ┆ ---       ┆ ---     ┆   ┆ mthd         ┆ ---        ┆ ---        ┆ rts          │\n"," │ i64 ┆ f64      ┆ str       ┆ str     ┆   ┆ ---          ┆ i64        ┆ i64        ┆ ---          │\n"," │     ┆          ┆           ┆         ┆   ┆ i64          ┆            ┆            ┆ i64          │\n"," ╞═════╪══════════╪═══════════╪═════════╪═══╪══════════════╪════════════╪════════════╪══════════════╡\n"," │ 1   ┆ 0.000003 ┆ udp       ┆ -       ┆ … ┆ 0            ┆ 1          ┆ 3          ┆ 0            │\n"," │ 2   ┆ 0.015833 ┆ tcp       ┆ -       ┆ … ┆ 0            ┆ 2          ┆ 6          ┆ 0            │\n"," │ 3   ┆ 0.000003 ┆ merit-inp ┆ -       ┆ … ┆ 0            ┆ 2          ┆ 4          ┆ 0            │\n"," │ 4   ┆ 0.000003 ┆ udp       ┆ dns     ┆ … ┆ 0            ┆ 32         ┆ 33         ┆ 0            │\n"," │ 5   ┆ 0.00106  ┆ udp       ┆ dns     ┆ … ┆ 0            ┆ 3          ┆ 3          ┆ 0            │\n"," │ …   ┆ …        ┆ …         ┆ …       ┆ … ┆ …            ┆ …          ┆ …          ┆ …            │\n"," │ 21  ┆ 0.916548 ┆ tcp       ┆ ftp     ┆ … ┆ 0            ┆ 2          ┆ 1          ┆ 0            │\n"," │ 22  ┆ 0.000009 ┆ udp       ┆ dns     ┆ … ┆ 0            ┆ 12         ┆ 20         ┆ 0            │\n"," │ 23  ┆ 1.005819 ┆ tcp       ┆ http    ┆ … ┆ 1            ┆ 3          ┆ 3          ┆ 0            │\n"," │ 24  ┆ 0.590464 ┆ tcp       ┆ ftp     ┆ … ┆ 0            ┆ 2          ┆ 2          ┆ 0            │\n"," │ 25  ┆ 0.000008 ┆ udp       ┆ dns     ┆ … ┆ 0            ┆ 27         ┆ 39         ┆ 0            │\n"," └─────┴──────────┴───────────┴─────────┴───┴──────────────┴────────────┴────────────┴──────────────┘)"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["# ***1. Data Pre-Processing (Task 1)***"],"metadata":{"id":"oYce1Z49mIsz"}},{"cell_type":"markdown","source":["TO-DO:\n","- [x] Convert DataFrame to np.float32\n","- [x] Sanity check if min-max rescaling will squash small number. Observation: np.float32 will pick up the difference in (small_number+1)/big_number, but not when small_number/(big_number+1). Looking at column feature contain big numbers like dur, sload, dload, rate: their value vary greater than 1000 between different samples. This is something np.float32 can pick up. Last but not least, this tells us that we shoudl add noise to dataset after normalisation, not before\n","- [x] Sanity check fuse rescale-normalise == rescale first then normalise"],"metadata":{"id":"PY_MbXp2cEsj"}},{"cell_type":"code","source":["############################################################\n","#put your code for data preprocessing here\n","############################################################\n","\n","import polars as pl\n","import numpy as np\n","\n","class NIDdataset():\n","    def __init__(\n","        self,\n","        train_file,\n","        val_file,\n","        test_file\n","    ):\n","        assert train_file.endswith(\".csv\"), print(\"train dataset should be either .csv in this project\")\n","        assert val_file.endswith(\".csv\"), print(\"val dataset should be either .csv in this project\")\n","        assert test_file.endswith(\".csv\"), print(\"test dataset should be either .csv in this project\")\n","\n","        if train_file.endswith(\".csv\") and val_file.endswith(\".csv\") and test_file.endswith(\".csv\"):\n","            train_df_encoded, val_df_encoded, test_df_encoded = self.encode_category_attribute(train_file, val_file, test_file, [\"proto\", \"service\", \"state\"])\n","            train_arr = train_df_encoded.to_numpy().astype(np.float32)\n","            val_arr = val_df_encoded.to_numpy().astype(np.float32)\n","            test_arr = test_df_encoded.to_numpy().astype(np.float32)\n","\n","            train_features = train_arr[:, 1:-1]\n","            val_features = val_arr[:, 1:-1]\n","            test_features = test_arr[:, 1:]\n","\n","            self.get_mean_std_after_rescaled(train_features)\n","\n","        self.train_set = np.concatenate([self._transform(train_features), train_arr[:, -1].reshape(-1, 1)], axis=1)\n","        self.val_set = np.concatenate([self._transform(val_features), val_arr[:, -1].reshape(-1, 1)], axis=1)\n","        self.test_set = self._transform(test_features)\n","\n","    def _transform(self, input: np.ndarray):\n","        processed_input = self.fused_rescale_normalise(input)\n","        return processed_input\n","\n","    def encode_category_attribute(self, csv_train, csv_val, csv_test, attribute_list):\n","        \"\"\"\n","        Args:\n","            csv_train (str): train set as .csv\n","            csv_val (str): val set as .csv\n","            csv_test (str): test set as .csv\n","\n","        Return:\n","            encoded version of train set, val set, test set as polars.DataFrame using encoding dictionary for train set\n","        \"\"\"\n","        df_train, df_val, df_test = polar_read_csv(csv_train, csv_val, csv_test)\n","\n","        attribute_dict = {}\n","        for attribute in attribute_list:\n","            if attribute in df_train.columns:\n","                unique_vals = (df_train.select(attribute).drop_nulls().unique().to_series().to_list())\n","                attribute_dict[attribute] = {val: idx for idx, val in enumerate(unique_vals)}\n","            else:\n","                print(f\"Warning: '{attribute}' not found in training CSV.\")\n","\n","        def apply_encoding(df, attribute_dict):\n","            for attribute, val_to_idx in attribute_dict.items():\n","                if attribute in df.columns:\n","                    df = df.with_columns(pl.col(attribute).replace(val_to_idx).alias(attribute))\n","            return df\n","        df_train_encoded = apply_encoding(df_train, attribute_dict)\n","        df_val_encoded = apply_encoding(df_val, attribute_dict)\n","        df_val_encoded = df_val_encoded.filter(pl.col(\"state\") != \"RST\")\n","        df_test_encoded = apply_encoding(df_test, attribute_dict)\n","\n","        return df_train_encoded, df_val_encoded, df_test_encoded\n","\n","    def get_mean_std_after_rescaled(self, x: np.ndarray):\n","        scale = np.max(x)\n","        x_rescaled = x/scale\n","        # usually we get mean, std per channel. But nb15 doesn't channel so we get 1 mean, std over anything to not destroy local inductive bias in train_features\n","        self.train_mean = np.mean(x_rescaled, axis=(0,1), keepdims=True)\n","        self.train_std = np.std(x_rescaled, axis=(0,1), keepdims=True)\n","\n","    def fused_rescale_normalise(self, x: np.ndarray):\n","        mean = self.train_mean.copy()\n","        std = self.train_std.copy()\n","        scaling_factor = np.max(x)\n","        return (x - mean*scaling_factor) / (std*scaling_factor)\n","\n","nb15_dataset = NIDdataset(\"UNSWNB15_training_coursework.csv\", \"UNSWNB15_testing1_coursework.csv\", \"UNSWNB15_testing2_coursework_no_label.csv\")\n","batch_size = 64\n","#print(f\"Train set shape: {nb15_dataset.train_set.shape}\")\n","#print(f\"Val set shape: {nb15_dataset.val_set.shape}\")\n","#print(f\"Test set shape: {nb15_dataset.test_set.shape}\")\n","print(nb15_dataset.train_mean)\n","print(nb15_dataset.train_std)\n","np.random.shuffle(nb15_dataset.train_set)\n","batches = [nb15_dataset.train_set[i:i+batch_size] for i in range(0, nb15_dataset.train_set.shape[0], batch_size)]\n","\n","# Check shapes of initial 3 batches.\n","for idx, batch in enumerate(batches[:3]):\n","    labels = batch[:, -1].reshape(-1, 1)\n","    features = np.expand_dims(batch[:, :-1], axis=-1)\n","    print(f\"\\nBatch {idx+1} shape:\", batch.shape)\n","    print(f\"Batch {idx+1} feature shape:\", features.shape)\n","    print(f\"Batch {idx+1} label shape:\", labels.shape)"],"metadata":{"id":"EpksctcIiBjB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744354831965,"user_tz":-60,"elapsed":480,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}},"outputId":"4f724a65-5134-48cd-91af-44b0f9602b11"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.01006994]]\n","[[0.07261028]]\n","\n","Batch 1 shape: (64, 43)\n","Batch 1 feature shape: (64, 42, 1)\n","Batch 1 label shape: (64, 1)\n","\n","Batch 2 shape: (64, 43)\n","Batch 2 feature shape: (64, 42, 1)\n","Batch 2 label shape: (64, 1)\n","\n","Batch 3 shape: (64, 43)\n","Batch 3 feature shape: (64, 42, 1)\n","Batch 3 label shape: (64, 1)\n"]}]},{"cell_type":"markdown","source":["# ***2. Model Implementation and Training (Task 2)***"],"metadata":{"id":"u4uQmeM_Albh"}},{"cell_type":"markdown","source":["TO-DO manually in numpy in order to implement MLP-Mixer:\n","- [x] Linear layer w/ manual backprop and init weight & bias w/ Kaiming uniform distribution\n","- [x] DropOut=0.1 w/ manual backprop\n","- [ ] Stochastic Depth={0->0.1}\n","- [x] LayerNorm w/ manual backprop\n","- [x] GeLU or Tanh w/ manual backprop\n","- [x] TokenMixer block\n","- [x] ChannelMixer block\n","- [x] Adam optimiser w/ β1 = 0.9, β2 = 0.999, weight decay = 0.03, lr=0.003\n","- [x] Binary Cross Entropy with logits\n","- [x] Optimiser.zero_grad()\n","- [ ] Gradient accumulation for more desired batch size = 4096"],"metadata":{"id":"2X0Rnga6nlrw"}},{"cell_type":"code","source":["############################################################\n","#put your code for model implementation and training here\n","############################################################\n","\n","import numpy as np\n","import math\n","from scipy.special import erf\n","\n","\n","# ---------- Init Linear weight and layer with Kaiming uniform distribution ----------\n","def calculate_gain(nonlinearity, param=None):\n","    # Inspired from https://github.com/pytorch/pytorch/blob/main/torch/nn/init.py#L72\n","    if nonlinearity in ['linear', 'conv1d', 'conv2d', 'conv3d',\n","                        'conv_transpose1d', 'conv_transpose2d', 'conv_transpose3d', 'sigmoid']:\n","        return 1.0\n","    elif nonlinearity == 'tanh':\n","        return 5.0 / 3\n","    elif nonlinearity == 'relu':\n","        return math.sqrt(2.0)\n","    elif nonlinearity == 'leaky_relu':\n","        negative_slope = 0.01 if param is None else param\n","        return math.sqrt(2.0 / (1 + negative_slope ** 2))\n","    else:\n","        raise ValueError(\"Unsupported nonlinearity {}\".format(nonlinearity))\n","\n","\n","def _calculate_correct_fan(tensor, mode):\n","    # Inspired from _calculate_fan_in_and_fan_out: https://github.com/pytorch/pytorch/blob/main/torch/nn/init.py#L345\n","    # Note that pytorch uses _calculate_correct_fan as API for _calculate_fan_in_and_fan_out so I merely remove the API\n","    if tensor.ndim < 2:\n","        raise ValueError(\"Fan in and fan out cannot be computed for tensor with fewer than 2 dimensions\")\n","    if mode == \"fan_in\":\n","        num_input_fmaps = tensor.shape[1]\n","        receptive_field_size = np.prod(tensor.shape[2:]) if tensor.ndim > 2 else 1\n","        return num_input_fmaps * receptive_field_size\n","    elif mode == \"fan_out\":\n","        num_output_fmaps = tensor.shape[0]\n","        receptive_field_size = np.prod(tensor.shape[2:]) if tensor.ndim > 2 else 1\n","        return num_output_fmaps * receptive_field_size\n","    else:\n","        raise ValueError(\"mode must be either 'fan_in' or 'fan_out'\")\n","\n","\n","def kaiming_uniform_(tensor, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\"):\n","    # Inspired from https://github.com/pytorch/pytorch/blob/main/torch/nn/init.py#L456\n","    fan = _calculate_correct_fan(tensor, mode)\n","    gain = calculate_gain(nonlinearity, a)\n","    std = gain / math.sqrt(fan)\n","    bound = math.sqrt(3.0) * std\n","    tensor[:] = np.random.uniform(-bound, bound, tensor.shape).astype(np.float32)\n","    return tensor\n","\n","\n","class Linear:\n","    # Inspired from https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/linear.py#L50\n","    def __init__(self, in_features, out_features, bias=True):\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = np.empty((out_features, in_features), dtype=np.float32)\n","        self.bias = np.empty((out_features,), dtype=np.float32) if bias else None\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        kaiming_uniform_(self.weight, a=math.sqrt(5), mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n","        if self.bias is not None:\n","            fan_in = _calculate_correct_fan(self.weight, \"fan_in\")\n","            bound = 1 / math.sqrt(fan_in)\n","            self.bias[:] = np.random.uniform(-bound, bound, self.bias.shape).astype(np.float32)\n","\n","    def forward(self, input):\n","        \"\"\"\n","            input (batch_size, N, in_features)\n","\n","            Returns np.ndarray (batch_size, N, out_features)\n","        \"\"\"\n","\n","        #output = np.einsum('bni,oi->bno', input, self.weight)\n","        #if self.bias is not None:\n","        #    output += self.bias.reshape(1, 1, -1)\n","        #return output\n","\n","        # Original implementation # Observed no difference between einsum and original implementation\n","        return np.matmul(np.ascontiguousarray(input), self.weight.T) + (self.bias if self.bias is not None else 0)\n","\n","    def backward(self, grad_output, input):\n","        \"\"\"\n","            grad_output (np.ndarray): Gradient w.r.t. output with shape (B, N, out_features)\n","            input (np.ndarray): Original input with shape (B, N, in_features)\n","\n","            Returns:\n","                grad_input (np.ndarray): Gradient w.r.t. input with shape (B, N, in_features)\n","                grad_weight (np.ndarray): Gradient w.r.t. weight with shape (out_features, in_features)\n","                grad_bias (np.ndarray or None): Gradient w.r.t. bias with shape (out_features,)\n","        \"\"\"\n","        grad_input = np.matmul(grad_output, self.weight)\n","        if input.ndim == 2:\n","            self.grad_weight = np.einsum('bi,bj->ij', grad_output, input)\n","            self.grad_bias = np.sum(grad_output, axis=0) if self.bias is not None else None\n","        elif input.ndim == 3:\n","            self.grad_weight = np.einsum('bnk,bnl->kl', grad_output, input)\n","            self.grad_bias = np.sum(grad_output, axis=(0, 1))\n","        # store self.grad_weight and self.grad_bias for optimiser.step later on\n","        return grad_input, self.grad_weight, self.grad_bias\n","\n","\n","eps = 1e-5\n","class LayerNorm:\n","    def __init__(self, dim):\n","        self.dim = dim\n","        self.weight = np.ones((dim,), dtype=np.float32)\n","        self.bias = np.zeros((dim,), dtype=np.float32)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: (B, N, embed_dim)\n","        Returns:\n","            out: layer-normalized activations, shape (B, T, embed_dim)\n","            cache: tuple of (x, self.w, mean, rstd) for backward pass.\n","        \"\"\"\n","        B, T, C = x.shape\n","        mean = np.sum(x, axis=-1, keepdims=True) / C           # (B, T, 1)\n","        xshift = x - mean\n","        var = np.sum(xshift ** 2, axis=-1, keepdims=True) / C  # (B, T, 1)\n","        rstd = (var + eps) ** (-0.5)                           # (B, T, 1)\n","        norm = xshift * rstd\n","        out = norm * self.weight + self.bias\n","        cache = (x, self.weight, mean, rstd)\n","        return out, cache\n","\n","    def backward(self, dout, cache):\n","        \"\"\"\n","        dout: upstream gradients, shape (B, N, embed_dim)\n","        cache: tuple of (x, w, mean, rstd) from forward pass.\n","        Returns:\n","            dx: gradient with respect to x, shape (B, T, embed_dim)\n","            dw: gradient with respect to self.w, shape (embed_dim,)\n","            db: gradient with respect to self.b, shape (embed_dim,)\n","        \"\"\"\n","        x, w, mean, rstd = cache\n","        norm = (x - mean) * rstd\n","        db = np.sum(dout, axis=(0, 1))\n","        dw = np.sum(dout * norm, axis=(0, 1))\n","        dnorm = dout * w\n","        dnorm_mean = np.mean(dnorm, axis=-1, keepdims=True)\n","        dx = dnorm - dnorm_mean - norm * np.mean(dnorm * norm, axis=-1, keepdims=True)\n","        dx *= rstd\n","        self.grad_weight = dw\n","        self.grad_bias = db\n","        return dx, dw, db\n","\n","\n","class Dropout:\n","    # Inspired from https://gist.github.com/nbertagnolli/35eb960d08c566523b4da599f6099b41\n","    # and https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L35\n","    def __init__(self, p=0.5):\n","        if p < 0 or p > 1:\n","            raise ValueError(\"p must be a probability in [0, 1].\")\n","        self.p = p\n","        self.training = True\n","        self.mask = None\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x (np.ndarray): Input array of any shape.\n","\n","        Returns:\n","            np.ndarray: Output array with dropout applied.\n","        \"\"\"\n","        if self.training:\n","            # Only generate a new mask if one hasn't been set externally.\n","            if self.mask is None or self.mask.shape != x.shape:\n","                self.mask = (np.random.rand(*x.shape) >= self.p).astype(x.dtype)\n","            return (x * self.mask) / (1 - self.p)\n","        else:\n","            self.mask = None\n","            return x\n","\n","    def backward(self, grad_output):\n","        if self.training:\n","            if self.mask is None:\n","                raise ValueError(\"Must run forward pass before backward pass in training mode.\")\n","            return (grad_output * self.mask) / (1 - self.p)\n","        else:\n","            return grad_output\n","\n","\n","class Reduce_np:\n","    # Practically the same as AveragePooling layer along specified axis\n","    def __init__(self, axis, reduction='mean'):\n","        self.axis = axis\n","        self.reduction = reduction\n","\n","    def forward(self, x):\n","        self.last_input = x.copy()\n","        if self.reduction == 'mean':\n","            return np.mean(x, axis=self.axis)\n","        else:\n","            raise NotImplementedError()\n","\n","    def backward(self, grad_output):\n","        shape = self.last_input.shape                         # (B, N, dim)\n","        scale = shape[self.axis]                              # axis = N in MLP_mixer\n","        grad_input = grad_output / scale\n","        grad_input = grad_input.reshape(grad_input.shape[0], 1, grad_input.shape[1])  # Reshape to (B, 1, dim) to broadcast along N dim\n","        return np.broadcast_to(grad_input, shape)             # broadcasts to (B, N, dim)\n","\n","\n","# ---------- Activation Function ----------\n","class GELU:\n","    # Inspired from https://github.com/oniani/ai/blob/main/activation/gelu.py#L4\n","    def __init__(self):\n","        self.ctx = {}\n","\n","    def forward(self, input):\n","        cdf = 0.5 * (1 + erf(input / np.sqrt(2)))\n","        self.ctx['input'] = input.copy()\n","        self.ctx['cdf'] = cdf.copy()\n","        return input * cdf\n","\n","    def backward(self, grad_output):\n","        input = self.ctx['input']\n","        cdf = self.ctx['cdf']\n","        pdf_val = 1 / np.sqrt(2 * np.pi) * np.exp(-0.5 * np.power(input, 2))\n","        grad_local = cdf + input * pdf_val\n","\n","        return grad_output * grad_local\n","\n","\n","class Tanh:\n","    def __init__(self):\n","        self.ctx = {}\n","\n","    def forward(self, input):\n","        output = np.tanh(input)\n","        self.ctx['output'] = output.copy()\n","        return output\n","\n","    def backward(self, grad_output):\n","        output = self.ctx['output']\n","        grad_input = grad_output * (1 - output**2)\n","        return grad_input\n","\n","\n","# ---------- Blocks ----------\n","class PreNormResidual:\n","    # Inspired from https://github.com/lucidrains/mlp-mixer-pytorch/blob/main/mlp_mixer_pytorch/mlp_mixer_pytorch.py#L7\n","    def __init__(self, dim, fn):\n","        self.norm = LayerNorm(dim)\n","        self.fn = fn\n","        # fn=TokenMixing/ChannelMixing: both return gradients w.r.t input, linear weight & bias, both have cache\n","\n","    def forward(self, x):\n","        norm_x, norm_cache = self.norm.forward(x)\n","        f_out = self.fn.forward(norm_x)\n","        # Store caches for backward\n","        self.cache = {'x': x.copy(), 'norm_cache': norm_cache, 'f_cache': self.fn.cache}\n","        return f_out + x\n","\n","    def backward(self, d_out):\n","        # d_out (B, N, dim)\n","        d_f, f_params_grad = self.fn.backward(d_out)\n","        # Backprop through norm: use stored norm cache\n","        d_norm, norm_dw, norm_db = self.norm.backward(d_f, self.cache['norm_cache'])\n","        self.norm.grad_weight = norm_dw\n","        self.norm.grad_bias = norm_db\n","        d_x = d_norm + d_out\n","\n","        return d_x, norm_dw, norm_db, f_params_grad\n","\n","\n","# TokenMixing operates along N dimension\n","class TokenMixing:\n","    def __init__(self, num_tokens, expansion_factor, dropout_p):\n","        inner_dim = int(num_tokens * expansion_factor)\n","        self.linear1 = Linear(num_tokens, inner_dim)\n","        self.activation_fn = GELU()\n","        # self.gelu = GELU()\n","        self.dropout1 = Dropout(dropout_p)\n","        self.linear2 = Linear(inner_dim, num_tokens)\n","        self.dropout2 = Dropout(dropout_p)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x_t = x transposed\n","        \"\"\"\n","        cache = {}\n","        x_t = np.transpose(x, (0, 2, 1))\n","        cache['x_t'] = x_t.copy()\n","        out_l1 = self.linear1.forward(x_t)\n","        cache['out_l1'] = out_l1.copy()\n","        #out_gelu = self.gelu.forward(out_l1)\n","        out_activation_fn = self.activation_fn.forward(out_l1)\n","        # cache['out_gelu'] = out_gelu.copy()\n","        out_drop1 = self.dropout1.forward(out_activation_fn)\n","        cache['out_drop1'] = out_drop1.copy()\n","        out_l2 = self.linear2.forward(out_drop1)\n","        cache['out_l2'] = out_l2.copy()\n","        out_drop2 = self.dropout2.forward(out_l2)\n","        cache['out_drop2'] = out_drop2.copy()\n","        out = np.transpose(out_drop2, (0, 2, 1))\n","        self.cache = cache\n","        return out\n","\n","    def backward(self, d_out):\n","        cache = self.cache\n","        d_drop2 = np.transpose(d_out, (0, 2, 1))\n","        d_l2 = self.dropout2.backward(d_drop2)\n","        d_drop1, grad_w2, grad_b2 = self.linear2.backward(d_l2, cache['out_drop1'])\n","        # d_gelu = self.dropout1.backward(d_drop1)\n","        d_activation_fn = self.dropout1.backward(d_drop1)\n","        # d_l1 = self.gelu.backward(d_gelu)\n","        d_x_t, grad_w1, grad_b1 = self.linear1.backward(self.activation_fn.backward(d_activation_fn), cache['x_t'])\n","        d_x = np.transpose(d_x_t, (0, 2, 1))\n","        self.params_grad = {'linear1': (grad_w1, grad_b1), 'linear2': (grad_w2, grad_b2)}\n","\n","        # Reset cache to prevent memory leak\n","        cache = {}\n","        return d_x, self.params_grad\n","\n","\n","# ChannelMixing operates along embedding dimension\n","class ChannelMixing:\n","    def __init__(self, dim, expansion_factor, dropout_p):\n","        inner_dim = int(dim * expansion_factor)\n","        self.linear1 = Linear(dim, inner_dim)\n","        # self.gelu = GELU()\n","        self.activation_fn = GELU()\n","        self.dropout1 = Dropout(dropout_p)\n","        self.linear2 = Linear(inner_dim, dim)\n","        self.dropout2 = Dropout(dropout_p)\n","\n","    def forward(self, x):\n","        cache = {}\n","        cache['x'] = x.copy()\n","        out_l1 = self.linear1.forward(x)\n","        cache['out_l1'] = out_l1.copy()\n","        # out_gelu = self.gelu.forward(out_l1)\n","        out_activation_fn = self.activation_fn.forward(out_l1)\n","        # cache['out_gelu'] = out_gelu.copy()\n","        out_drop1 = self.dropout1.forward(out_activation_fn)\n","        cache['out_drop1'] = out_drop1.copy()\n","        out_l2 = self.linear2.forward(out_drop1)\n","        cache['out_l2'] = out_l2.copy()\n","        out_drop2 = self.dropout2.forward(out_l2)\n","        #cache['out_drop2'] = out_drop2.copy()\n","        self.cache = cache\n","        return out_drop2\n","\n","    def backward(self, d_out):\n","        cache = self.cache\n","        d_drop2 = self.dropout2.backward(d_out)\n","        d_drop1, grad_w2, grad_b2 = self.linear2.backward(d_drop2, cache['out_drop1'])\n","        d_activation_fn = self.dropout1.backward(d_drop1)\n","        # d_gelu = self.dropout1.backward(d_drop1)\n","        d_l1, grad_w1, grad_b1 = self.linear1.backward(self.activation_fn.backward(d_activation_fn), cache['x'])\n","        self.params_grad = {'linear1': (grad_w1, grad_b1), 'linear2': (grad_w2, grad_b2)}\n","\n","        # Reset cache to prevent memory leak\n","        cache = {}\n","        return d_l1, self.params_grad\n","\n","\n","# ---------- Model ----------\n","class MLPMixer:\n","    def __init__(self, num_tokens, input_dim, dim, depth, num_classes,\n","                 expansion_factor=4, expansion_factor_token=0.5, dropout_p=0.):\n","        \"\"\"\n","        Args:\n","            num_tokens (int): Number of tokens (N).\n","            input_dim (int): Input token dimension.\n","            dim (int): Mixer embedding dimension.\n","            depth (int): Number of mixer layers.\n","            num_classes (int): Number of classes for classification.\n","            expansion_factor (float): Expansion factor for token mixing.\n","            expansion_factor_token (float): Expansion factor for channel mixing.\n","            dropout_p (float): Dropout probability.\n","        \"\"\"\n","        self.num_tokens = num_tokens\n","        self.input_dim = input_dim\n","        self.dim = dim\n","        self.depth = depth\n","        self.num_classes = num_classes\n","        self.dropout_p = dropout_p\n","        self.proj = Linear(input_dim, dim) if input_dim != dim else None\n","        self.mixer_layers = []\n","        for _ in range(depth):\n","            token_mixing = PreNormResidual(dim, TokenMixing(num_tokens, expansion_factor, dropout_p))\n","            channel_mixing = PreNormResidual(dim, ChannelMixing(dim, expansion_factor_token, dropout_p))\n","            self.mixer_layers.append((token_mixing, channel_mixing))\n","        self.layer_norm = LayerNorm(dim)\n","        self.reduce = Reduce_np(axis=1, reduction='mean')\n","        self.classifier = Linear(dim, num_classes)\n","        self.cache = {}\n","\n","    def forward(self, x):\n","        if self.proj is not None:\n","            self.cache['proj_in'] = x.copy()\n","            x = self.proj.forward(x)\n","        else:\n","            self.cache['proj_in'] = None\n","        self.cache['mixer'] = []\n","\n","        for token_mixing, channel_mixing in self.mixer_layers:\n","            mixer_cache = {}\n","            mixer_cache['in'] = x.copy()\n","            t_out = token_mixing.forward(x)\n","            mixer_cache['token_cache'] = token_mixing.cache\n","            c_out = channel_mixing.forward(t_out)\n","            mixer_cache['channel_cache'] = channel_mixing.cache\n","            self.cache['mixer'].append(mixer_cache)\n","            x = c_out\n","\n","        self.cache['ln_in'] = x.copy()\n","        x_ln, ln_cache = self.layer_norm.forward(x)\n","        self.cache['ln_cache'] = ln_cache\n","        self.cache['reduce_in'] = x_ln.copy()\n","        x_red = self.reduce.forward(x_ln)\n","        self.cache['clf_in'] = x_red.copy()\n","        x_cls = self.classifier.forward(x_red)\n","        self.cache['output'] = x_cls.copy()\n","        return x_cls\n","\n","    def backward(self, grad_output):\n","        d_clf, _ , _ = self.classifier.backward(grad_output, self.cache['clf_in'])\n","        d_reduce = self.reduce.backward(d_clf)\n","        d_ln, _ , _ = self.layer_norm.backward(d_reduce, self.cache['ln_cache'])\n","        grad = d_ln\n","\n","        for (token_mixing, channel_mixing), mixer_cache in zip(self.mixer_layers[::-1],\n","                                                               self.cache['mixer'][::-1]):\n","            grad, _, _, _ = channel_mixing.backward(grad)\n","            grad, _, _, _ = token_mixing.backward(grad)\n","\n","        if self.proj is not None:\n","            grad, _ , _ = self.proj.backward(grad, self.cache['proj_in'])\n","\n","        return grad\n","\n","\n","# ---------- Loss ----------\n","class BCEWithLogits_np:\n","    # Inspired from https://github.com/pytorch/pytorch/blob/c64e006fc399d528bb812ae589789d0365f3daf4/aten/src/ATen/native/Loss.cpp#L214-L259\n","    # binary cross-entropy loss in a more numerically stable way using log-sum-exp when integrating sigmoid ops under this class\n","    def __init__(self, weight=None, pos_weight=None, reduction='mean'):\n","        \"\"\"\n","        Args:\n","            weight (np.ndarray or None): Optional weight tensor, broadcastable to input.\n","            pos_weight (np.ndarray or None): Optional weight for positive examples.\n","            reduction (str): 'mean' or 'sum'\n","        \"\"\"\n","        self.weight = weight\n","        self.pos_weight = pos_weight\n","        self.reduction = reduction\n","        self.cache = {}\n","\n","    def forward(self, input, target):\n","        \"\"\"\n","        Args:\n","            input (np.ndarray): logits (B, 2)\n","            target (np.ndarray): labels (B, 2)\n","        Returns:\n","            loss (float or np.ndarray): reduced loss value if reduction is 'mean' or 'sum'; elementwise loss if reduction is 'none'.\n","        \"\"\"\n","        max_val = np.maximum(-input, 0)\n","\n","        if self.pos_weight is not None:\n","            log_weight = 1 + (self.pos_weight - 1) * target\n","            lse = np.log(np.exp(-max_val) + np.exp(-input - max_val))\n","            loss = (1 - target) * input + log_weight * (lse + max_val)\n","        else:\n","            loss = (1 - target) * input + max_val + np.log(np.exp(-max_val) + np.exp(-input - max_val))\n","\n","        if self.weight is not None:\n","            loss = loss * self.weight\n","\n","        self.cache['input'] = input.copy()\n","        self.cache['target'] = target.copy()\n","\n","        if self.reduction == 'mean':\n","            return np.mean(loss)\n","        elif self.reduction == 'sum':\n","            return np.sum(loss)\n","\n","    def backward(self, grad_output=1.0):\n","        input = self.cache['input']\n","        target = self.cache['target']\n","\n","        # Compute sigmoid(input) in a stable way.\n","        sig = 1 / (1 + np.exp(-input))\n","        if self.pos_weight is not None:\n","            grad_input = (sig * (self.pos_weight * target + (1 - target)) - self.pos_weight * target)\n","        else:\n","            grad_input = sig - target\n","\n","        if self.weight is not None:\n","            grad_input = grad_input * self.weight\n","\n","        # If reduction is mean, scale the gradient by 1/numel.\n","        if self.reduction == 'mean':\n","            grad_input = grad_input * grad_output / input.size\n","        else:\n","            grad_input = grad_input * grad_output\n","\n","        return grad_input\n","\n","\n","# ---------- Optimiser ----------\n","class ADAM_np:\n","    # Inspired from https://gist.github.com/aerinkim/dfe3da1000e67aced1c7d9279351cb88\n","    \"\"\"\n","        Adam optimizer using NumPy, operating on a list of parameter 5-tuples:\n","            (p, param_attr, mod, grad, grad_attr)\n","        where:\n","        - p is the parameter array (e.g. mod.weight or mod.bias)\n","        - param_attr is \"weight\" or \"bias\"\n","        - mod is the module that holds this parameter\n","        - grad is the current gradient stored in mod (may be None if not computed yet)\n","        - grad_attr is the name of the attribute where the gradient is stored (e.g. \"grad_weight\")\n","    \"\"\"\n","    def __init__(self, model, lr=1e-3, betas=(0.9, 0.99), eps=1e-8, weight_decay=0):\n","        self.param_tuples = self.get_pointers_to_param_and_grad(model)\n","        self.lr = lr\n","        self.beta1, self.beta2 = betas\n","        self.eps = eps\n","        self.weight_decay = weight_decay\n","\n","        # Create a state for each parameter\n","        self.state = {}\n","        for (p, param_attr, mod, grad, grad_attr) in self.param_tuples:\n","            self.state[id(p)] = {\n","                'step': 0,\n","                'exp_avg': np.zeros_like(p),\n","                'exp_avg_sq': np.zeros_like(p)\n","            }\n","\n","    def step(self):\n","        \"\"\"\n","        Update p in each tuple in self.param_tuples provided grad\n","        Also update state\n","        \"\"\"\n","        for (p, param_attr, mod, grad, grad_attr) in self.param_tuples:\n","            # Retrieve the gradient dynamically\n","            grad = getattr(mod, grad_attr)\n","            state = self.state[id(p)]\n","            state['step'] += 1\n","\n","            # Apply weight decay (L2 regularization)\n","            if self.weight_decay != 0:\n","                grad = grad + self.weight_decay * p\n","\n","            # Update exponential moving averages.\n","            state['exp_avg'] = self.beta1 * state['exp_avg'] + (1 - self.beta1) * grad\n","            state['exp_avg_sq'] = self.beta2 * state['exp_avg_sq'] + (1 - self.beta2) * (grad * grad)\n","            denom = np.sqrt(state['exp_avg_sq']) + self.eps\n","\n","            # Bias corrections.\n","            bias_correction1 = 1 / (1 - self.beta1 ** state['step'])\n","            bias_correction2 = 1 / (1 - self.beta2 ** state['step'])\n","            adapted_lr = self.lr * bias_correction1 / math.sqrt(bias_correction2)\n","\n","            # Update parameter in place.\n","            p[:] = p - adapted_lr * (state['exp_avg'] / denom)\n","\n","    def copy_updated_params(self):\n","        \"\"\"\n","        Explicitly copy the updated parameter array p back to the module's parameters in place.\n","        This is done with in-place assignment to ensure the object identity is preserved.\n","        \"\"\"\n","        for (p, param_attr, mod, grad, grad_attr) in self.param_tuples:\n","            if param_attr == \"weight\" and hasattr(mod, \"weight\"):\n","                mod.weight[...] = np.copy(p)\n","            elif param_attr == \"bias\" and hasattr(mod, \"bias\"):\n","                mod.bias[...] = np.copy(p)\n","\n","    def get_pointers_to_param_and_grad(self, module, visited=None):\n","        \"\"\"\n","        Recursively traverses the module hierarchy and returns this tuple in the exact order:\n","        (p, param_attr, module, grad, grad_attr)\n","        - p is np.float32 parameter, either weight or bias of linear layer or layernorm,\n","        - param_attr is a string that tells where to put p in optimiser.step equation\n","        - module is reference pointer to the module that holds this parameter\n","        - grad is np.float32 parameter, either grad_weight or grad_bias of linear layer or layernorm\n","        - grad_attr is a string that tells where to put grad in optimiser.step equation\n","\n","        Skips keys that are irrelevant or duplicative (like params_grad) during recursive search\n","        \"\"\"\n","        if visited is None:\n","            visited = set()\n","        tuples = []\n","        if id(module) in visited:\n","            return tuples\n","        visited.add(id(module))\n","\n","        # --- Get reference pointers to the weight and grad_weight, or bias and grad_bias of a linear layer\n","        if hasattr(module, 'weight') and isinstance(module.weight, np.ndarray):\n","            tuples.append((getattr(module, 'weight', None),\n","                        \"weight\",\n","                        module,\n","                        getattr(module, 'grad_weight', None),\n","                        \"grad_weight\")\n","                        )\n","        if hasattr(module, 'bias') and module.bias is not None and isinstance(module.bias, np.ndarray):\n","            tuples.append((getattr(module, 'bias', None),\n","                        \"bias\",\n","                        module,\n","                        getattr(module, 'grad_bias', None),\n","                        \"grad_bias\")\n","                        )\n","\n","        # ---  Get reference pointers to the weight and grad_weight, or bias and grad_bias of a layernorm\n","        if hasattr(module, 'norm'):\n","            norm_mod = module.norm\n","            if hasattr(norm_mod, 'weight') and isinstance(norm_mod.weight, np.ndarray):\n","                tuples.append((getattr(norm_mod, 'weight', None),\n","                            \"weight\",\n","                            norm_mod,\n","                            getattr(norm_mod, 'grad_weight', None),\n","                            \"grad_weight\")\n","                            )\n","            if hasattr(norm_mod, 'bias') and norm_mod.bias is not None and isinstance(norm_mod.bias, np.ndarray):\n","                tuples.append((getattr(norm_mod, 'bias', None),\n","                            \"bias\",\n","                            norm_mod,\n","                            getattr(norm_mod, 'grad_bias', None),\n","                            \"grad_bias\")\n","                            )\n","\n","        # --- Recursively explore submodules stored as attributes.\n","        for key, value in module.__dict__.items():\n","            if key in {'cache', 'ctx', 'params_grad'}:\n","                continue\n","            if hasattr(value, 'forward') and callable(value.forward) and value is not module:\n","                tuples.extend(self.get_pointers_to_param_and_grad(value, visited))\n","            elif isinstance(value, (list, tuple)):\n","                for item in value:\n","                    if hasattr(item, 'forward') and callable(item.forward):\n","                        tuples.extend(self.get_pointers_to_param_and_grad(item, visited))\n","                    elif isinstance(item, (list, tuple)):\n","                        for subitem in item:\n","                            if hasattr(subitem, 'forward') and callable(subitem.forward):\n","                                tuples.extend(self.get_pointers_to_param_and_grad(subitem, visited))\n","\n","        self.param_tuples = tuples\n","        return tuples\n","\n","    def refresh_grad_per_backprop(self, model):\n","        self.param_tuples = self.get_pointers_to_param_and_grad(model)\n","\n","\n","# ---------- Optimiser.zero_grad() ----------\n","def clear_auxiliary(module):\n","    \"\"\"\n","    Recursively clears auxiliary attributes from the module and its submodules.\n","    This includes attributes with keys 'cache', 'ctx', 'params_grad', and 'mask'.\n","\n","    For each key:\n","      - If its value is a dict, it is set to {}.\n","      - Otherwise, it is set to None.\n","    \"\"\"\n","    aux_keys = ('cache', 'ctx', 'params_grad', 'mask')\n","    # Clear any auxiliary attribute on this module.\n","    for key in aux_keys:\n","        if key in module.__dict__:\n","            current = module.__dict__[key]\n","            if isinstance(current, dict):\n","                setattr(module, key, {})\n","            else:\n","                setattr(module, key, None)\n","\n","    # Now recursively traverse submodules.\n","    for key, value in module.__dict__.items():\n","        # Skip aux keys already handled.\n","        if key in aux_keys:\n","            continue\n","\n","        # If the attribute is a list or tuple, iterate through its items.\n","        if isinstance(value, (list, tuple)):\n","            for item in value:\n","                if isinstance(item, tuple):\n","                    for subitem in item:\n","                        if hasattr(subitem, 'forward') and callable(subitem.forward):\n","                            clear_auxiliary(subitem)\n","                elif hasattr(value, 'forward') and callable(value.forward):\n","                    # Unlikely: this checks if the entire list itself has a forward().\n","                    clear_auxiliary(value)\n","                elif hasattr(item, 'forward') and callable(item.forward):\n","                    clear_auxiliary(item)\n","        # If the attribute is a submodule (has callable forward), recurse.\n","        elif hasattr(value, 'forward') and callable(value.forward) and value is not module:\n","            clear_auxiliary(value)\n","\n","\n","# ---------- After training ----------\n","def save_model_and_optimiser(model, optimiser, filename=\"model_optim_state.npy\"):\n","    \"\"\"\n","    Save model parameters and optimizer state to a .npy file.\n","    The final dictionary has the form:\n","\n","        {\n","           \"model_state\": { key: parameter_array, ... },\n","           \"optimizer_state\": optimizer.state\n","        }\n","\n","    Args:\n","        model: Your MLPMixer instance.\n","        optimizer: Your ADAM_np instance.\n","        filename: The file name to save the state (default: \"model_optim_state.npy\").\n","    \"\"\"\n","    param_tuples = optimiser.get_pointers_to_param_and_grad(model)\n","\n","    model_state = {}\n","    # Create a unique key for each parameter.\n","    for (p, param_attr, mod, grad, grad_attr) in param_tuples:\n","        key = f\"{mod.__class__.__name__}_{param_attr}_{id(p)}\"\n","        model_state[key] = p.copy()\n","\n","    optimiser_state = optimiser.state.copy()\n","\n","    state = {\n","        \"model_state\": model_state,\n","        \"optimizer_state\": optimiser_state\n","    }\n","\n","    # Save to a .npy file (when loading, use allow_pickle=True).\n","    np.save(filename, state)\n","    print(f\"Model and optimizer state saved to {filename}\")\n","\n","\n","# ---------- Model, optimiser, loss instantiation ----------\n","model = MLPMixer(num_tokens=42, input_dim=1, dim=48, depth=10, num_classes=1, dropout_p=0.1)\n","loss_fn_np = BCEWithLogits_np(reduction='mean')\n","optimiser_np = ADAM_np(model, lr=0.01, weight_decay=0)\n","# print(optimiser_np.param_tuples)\n","\n","\n","# ---------- Training loop ----------\n","batch_size = 64\n","num_epochs = 34\n","train_losses = []\n","val_losses = []\n","train_iter = 0\n","val_iter = 0\n","\n","import pdb\n","for epoch in range(num_epochs):\n","    np.random.shuffle(nb15_dataset.train_set)\n","    batches = [nb15_dataset.train_set[i:i+batch_size] for i in range(0, nb15_dataset.train_set.shape[0], batch_size)]\n","    print(\"\\nEpoch:\", epoch)\n","\n","    total_train_loss_per_epoch = 0.0\n","    for batch in batches:\n","        labels = batch[:, -1].reshape(-1, 1)\n","        features = np.expand_dims(batch[:, :-1], axis=-1)\n","        logits = model.forward(features)\n","\n","        batch_train_loss = loss_fn_np.forward(logits, labels)\n","\n","        grad_logits = loss_fn_np.backward()\n","        _ = model.backward(grad_logits)\n","\n","        #before_step_mixer_linear = np.copy(model.mixer_layers[0][0].fn.linear1.weight)\n","        optimiser_np.refresh_grad_per_backprop(model)\n","        #print(optimiser_np.param_tuples)\n","        #pdb.set_trace()\n","        optimiser_np.step()\n","        #after_step_mixer_linear = model.mixer_layers[0][0].fn.linear1.weight\n","        #print(\"Max abs diff between before and after stepping (should be a small difference):\", np.max(np.abs(before_step_mixer_linear - after_step_mixer_linear)))\n","        optimiser_np.copy_updated_params()\n","        #after_step_and_copy_mixer_linear = model.mixer_layers[0][0].fn.linear1.weight\n","        #print(\"Max abs diff between before and after update and copy (should be 0):\", np.max(np.abs(after_step_and_copy_mixer_linear - after_step_mixer_linear)))\n","        #pdb.set_trace()\n","\n","        clear_auxiliary(model)\n","        total_train_loss_per_epoch += batch_train_loss\n","\n","        train_iter += 1\n","        if train_iter % 50 == 0:\n","            print(f\"Train Iteration {train_iter}, Loss: {batch_train_loss:.8f}\")\n","    avg_train_loss_per_epoch = total_train_loss_per_epoch / len(batches)\n","    train_losses.append(avg_train_loss_per_epoch)\n","\n","    total_val_loss_per_epoch = 0.0\n","    val_batches = [nb15_dataset.val_set[i:i+batch_size] for i in range(0, nb15_dataset.val_set.shape[0], batch_size)]\n","    for val_batch in val_batches:\n","        labels = val_batch[:, -1].reshape(-1, 1)\n","        features = np.expand_dims(val_batch[:, :-1], axis=-1)\n","        logits = model.forward(features)\n","\n","        batch_val_loss = loss_fn_np.forward(logits, labels)\n","\n","        total_val_loss_per_epoch += batch_val_loss\n","\n","        val_iter += 1\n","        if val_iter % 50 == 0:\n","            print(f\"Val Iteration {val_iter}, Loss: {batch_val_loss:.8f}\")\n","\n","    avg_val_loss_per_epoch = total_val_loss_per_epoch / len(val_batches)\n","    val_losses.append(avg_val_loss_per_epoch)\n","\n","print(\"Average loss:\", np.mean(train_losses))\n","save_model_and_optimiser(model, optimiser_np)"],"metadata":{"id":"yzR1gaj0BZlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744370708338,"user_tz":-60,"elapsed":15850837,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}},"outputId":"12598f60-f14d-4e01-9902-3b3e6929be6a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 0\n","Train Iteration 50, Loss: 0.62727369\n","Train Iteration 100, Loss: 0.55524590\n","Train Iteration 150, Loss: 0.47007962\n","Train Iteration 200, Loss: 0.47432268\n","Train Iteration 250, Loss: 0.58601827\n","Train Iteration 300, Loss: 0.47609859\n","Val Iteration 50, Loss: 0.54719018\n","\n","Epoch: 1\n","Train Iteration 350, Loss: 0.54614159\n","Train Iteration 400, Loss: 0.54497079\n","Train Iteration 450, Loss: 0.57369857\n","Train Iteration 500, Loss: 0.45389511\n","Train Iteration 550, Loss: 0.50073429\n","Train Iteration 600, Loss: 0.51342104\n","Val Iteration 100, Loss: 0.62025088\n","\n","Epoch: 2\n","Train Iteration 650, Loss: 0.54641933\n","Train Iteration 700, Loss: 0.58364668\n","Train Iteration 750, Loss: 0.56350443\n","Train Iteration 800, Loss: 0.48119427\n","Train Iteration 850, Loss: 0.47673279\n","Train Iteration 900, Loss: 0.55519327\n","Val Iteration 150, Loss: 0.46794233\n","\n","Epoch: 3\n","Train Iteration 950, Loss: 0.58025893\n","Train Iteration 1000, Loss: 0.61781445\n","Train Iteration 1050, Loss: 0.62832171\n","Train Iteration 1100, Loss: 0.56682327\n","Train Iteration 1150, Loss: 0.51565882\n","Train Iteration 1200, Loss: 0.51982598\n","Train Iteration 1250, Loss: 0.59849858\n","Val Iteration 200, Loss: 0.56161283\n","Val Iteration 250, Loss: 0.52785050\n","\n","Epoch: 4\n","Train Iteration 1300, Loss: 0.54877078\n","Train Iteration 1350, Loss: 0.51282990\n","Train Iteration 1400, Loss: 0.54003797\n","Train Iteration 1450, Loss: 0.44973424\n","Train Iteration 1500, Loss: 0.54793466\n","Train Iteration 1550, Loss: 0.55659285\n","Val Iteration 300, Loss: 0.50965821\n","\n","Epoch: 5\n","Train Iteration 1600, Loss: 0.52448098\n","Train Iteration 1650, Loss: 0.65541543\n","Train Iteration 1700, Loss: 0.44278065\n","Train Iteration 1750, Loss: 0.52406385\n","Train Iteration 1800, Loss: 0.48284295\n","Train Iteration 1850, Loss: 0.46161558\n","Val Iteration 350, Loss: 0.53484115\n","\n","Epoch: 6\n","Train Iteration 1900, Loss: 0.59195318\n","Train Iteration 1950, Loss: 0.52543871\n","Train Iteration 2000, Loss: 0.47028151\n","Train Iteration 2050, Loss: 0.47157061\n","Train Iteration 2100, Loss: 0.54571292\n","Train Iteration 2150, Loss: 0.57633904\n","Val Iteration 400, Loss: 0.60860631\n","\n","Epoch: 7\n","Train Iteration 2200, Loss: 0.40702537\n","Train Iteration 2250, Loss: 0.54861367\n","Train Iteration 2300, Loss: 0.58570151\n","Train Iteration 2350, Loss: 0.57791259\n","Train Iteration 2400, Loss: 0.57504594\n","Train Iteration 2450, Loss: 0.57760134\n","Train Iteration 2500, Loss: 0.48998018\n","Val Iteration 450, Loss: 0.58269423\n","Val Iteration 500, Loss: 0.41981553\n","\n","Epoch: 8\n","Train Iteration 2550, Loss: 0.43380078\n","Train Iteration 2600, Loss: 0.78570432\n","Train Iteration 2650, Loss: 0.57350827\n","Train Iteration 2700, Loss: 0.52248818\n","Train Iteration 2750, Loss: 0.42419770\n","Train Iteration 2800, Loss: 0.56709545\n","Val Iteration 550, Loss: 0.50828774\n","\n","Epoch: 9\n","Train Iteration 2850, Loss: 0.60132696\n","Train Iteration 2900, Loss: 0.47217839\n","Train Iteration 2950, Loss: 0.51032298\n","Train Iteration 3000, Loss: 0.62996415\n","Train Iteration 3050, Loss: 0.55651151\n","Train Iteration 3100, Loss: 0.48700206\n","Val Iteration 600, Loss: 0.45000074\n","\n","Epoch: 10\n","Train Iteration 3150, Loss: 0.51589512\n","Train Iteration 3200, Loss: 0.47363950\n","Train Iteration 3250, Loss: 0.45359719\n","Train Iteration 3300, Loss: 0.61546748\n","Train Iteration 3350, Loss: 0.59556279\n","Train Iteration 3400, Loss: 0.51288729\n","Val Iteration 650, Loss: 0.41185964\n","\n","Epoch: 11\n","Train Iteration 3450, Loss: 0.54964314\n","Train Iteration 3500, Loss: 0.53955465\n","Train Iteration 3550, Loss: 0.47122104\n","Train Iteration 3600, Loss: 0.54841441\n","Train Iteration 3650, Loss: 0.59746645\n","Train Iteration 3700, Loss: 0.52612549\n","Train Iteration 3750, Loss: 0.60806494\n","Val Iteration 700, Loss: 0.47516761\n","Val Iteration 750, Loss: 0.43153525\n","\n","Epoch: 12\n","Train Iteration 3800, Loss: 0.60434178\n","Train Iteration 3850, Loss: 0.52569634\n","Train Iteration 3900, Loss: 0.53126190\n","Train Iteration 3950, Loss: 0.60272342\n","Train Iteration 4000, Loss: 0.42064893\n","Train Iteration 4050, Loss: 0.48937342\n","Val Iteration 800, Loss: 0.53123011\n","\n","Epoch: 13\n","Train Iteration 4100, Loss: 0.51511133\n","Train Iteration 4150, Loss: 0.50871386\n","Train Iteration 4200, Loss: 0.57193077\n","Train Iteration 4250, Loss: 0.60901689\n","Train Iteration 4300, Loss: 0.56105847\n","Train Iteration 4350, Loss: 0.54449002\n","Val Iteration 850, Loss: 0.44529982\n","\n","Epoch: 14\n","Train Iteration 4400, Loss: 0.49435442\n","Train Iteration 4450, Loss: 0.49685118\n","Train Iteration 4500, Loss: 0.44835363\n","Train Iteration 4550, Loss: 0.50224054\n","Train Iteration 4600, Loss: 0.44218079\n","Train Iteration 4650, Loss: 0.52170165\n","Val Iteration 900, Loss: 0.42743295\n","\n","Epoch: 15\n","Train Iteration 4700, Loss: 0.43958195\n","Train Iteration 4750, Loss: 0.40167393\n","Train Iteration 4800, Loss: 0.40817212\n","Train Iteration 4850, Loss: 0.67837093\n","Train Iteration 4900, Loss: 0.56324436\n","Train Iteration 4950, Loss: 0.41922956\n","Train Iteration 5000, Loss: 0.47504442\n","Val Iteration 950, Loss: 0.33540477\n","Val Iteration 1000, Loss: 0.47468011\n","\n","Epoch: 16\n","Train Iteration 5050, Loss: 0.53780463\n","Train Iteration 5100, Loss: 0.44765582\n","Train Iteration 5150, Loss: 0.43716590\n","Train Iteration 5200, Loss: 0.44501037\n","Train Iteration 5250, Loss: 0.51018094\n","Train Iteration 5300, Loss: 0.40947712\n","Val Iteration 1050, Loss: 0.47255685\n","\n","Epoch: 17\n","Train Iteration 5350, Loss: 0.53550015\n","Train Iteration 5400, Loss: 0.50429704\n","Train Iteration 5450, Loss: 0.44216428\n","Train Iteration 5500, Loss: 0.55428081\n","Train Iteration 5550, Loss: 0.41815195\n","Train Iteration 5600, Loss: 0.47677642\n","Val Iteration 1100, Loss: 0.52675141\n","\n","Epoch: 18\n","Train Iteration 5650, Loss: 0.41541085\n","Train Iteration 5700, Loss: 0.44604837\n","Train Iteration 5750, Loss: 0.52940710\n","Train Iteration 5800, Loss: 0.48591244\n","Train Iteration 5850, Loss: 0.37454346\n","Train Iteration 5900, Loss: 0.36966218\n","Val Iteration 1150, Loss: 0.29968491\n","\n","Epoch: 19\n","Train Iteration 5950, Loss: 0.42411725\n","Train Iteration 6000, Loss: 0.53447709\n","Train Iteration 6050, Loss: 0.47687123\n","Train Iteration 6100, Loss: 0.52026201\n","Train Iteration 6150, Loss: 0.65335360\n","Train Iteration 6200, Loss: 0.45478213\n","Train Iteration 6250, Loss: 0.34307509\n","Val Iteration 1200, Loss: 0.37267157\n","Val Iteration 1250, Loss: 0.43141301\n","\n","Epoch: 20\n","Train Iteration 6300, Loss: 0.48969386\n","Train Iteration 6350, Loss: 0.41162490\n","Train Iteration 6400, Loss: 0.53127008\n","Train Iteration 6450, Loss: 0.48972160\n","Train Iteration 6500, Loss: 0.40391590\n","Train Iteration 6550, Loss: 0.47148844\n","Val Iteration 1300, Loss: 0.44176612\n","\n","Epoch: 21\n","Train Iteration 6600, Loss: 0.39250378\n","Train Iteration 6650, Loss: 0.36617356\n","Train Iteration 6700, Loss: 0.46027303\n","Train Iteration 6750, Loss: 0.42759576\n","Train Iteration 6800, Loss: 0.40750706\n","Train Iteration 6850, Loss: 0.52513169\n","Val Iteration 1350, Loss: 0.41169546\n","\n","Epoch: 22\n","Train Iteration 6900, Loss: 0.34715636\n","Train Iteration 6950, Loss: 0.54561473\n","Train Iteration 7000, Loss: 0.40991078\n","Train Iteration 7050, Loss: 0.47189211\n","Train Iteration 7100, Loss: 0.45413188\n","Train Iteration 7150, Loss: 0.50609034\n","Val Iteration 1400, Loss: 0.31106446\n","\n","Epoch: 23\n","Train Iteration 7200, Loss: 0.44870007\n","Train Iteration 7250, Loss: 0.48721924\n","Train Iteration 7300, Loss: 0.53831493\n","Train Iteration 7350, Loss: 0.37413843\n","Train Iteration 7400, Loss: 0.45225039\n","Train Iteration 7450, Loss: 0.44295352\n","Train Iteration 7500, Loss: 0.52080229\n","Val Iteration 1450, Loss: 0.39767831\n","Val Iteration 1500, Loss: 0.36059022\n","\n","Epoch: 24\n","Train Iteration 7550, Loss: 0.43274516\n","Train Iteration 7600, Loss: 0.44665243\n","Train Iteration 7650, Loss: 0.48297978\n","Train Iteration 7700, Loss: 0.40971211\n","Train Iteration 7750, Loss: 0.43907680\n","Train Iteration 7800, Loss: 0.46585778\n","Val Iteration 1550, Loss: 0.40741375\n","\n","Epoch: 25\n","Train Iteration 7850, Loss: 0.45691749\n","Train Iteration 7900, Loss: 0.45997738\n","Train Iteration 7950, Loss: 0.58592219\n","Train Iteration 8000, Loss: 0.46535868\n","Train Iteration 8050, Loss: 0.50463606\n","Train Iteration 8100, Loss: 0.39568054\n","Val Iteration 1600, Loss: 0.39166638\n","\n","Epoch: 26\n","Train Iteration 8150, Loss: 0.52354087\n","Train Iteration 8200, Loss: 0.31642831\n","Train Iteration 8250, Loss: 0.48967522\n","Train Iteration 8300, Loss: 0.35106639\n","Train Iteration 8350, Loss: 0.45522803\n","Train Iteration 8400, Loss: 0.48985415\n","Train Iteration 8450, Loss: 0.48884554\n","Val Iteration 1650, Loss: 0.40788864\n","Val Iteration 1700, Loss: 0.43310255\n","\n","Epoch: 27\n","Train Iteration 8500, Loss: 0.49134927\n","Train Iteration 8550, Loss: 0.51106664\n","Train Iteration 8600, Loss: 0.38739485\n","Train Iteration 8650, Loss: 0.43981781\n","Train Iteration 8700, Loss: 0.39871528\n","Train Iteration 8750, Loss: 0.45253007\n","Val Iteration 1750, Loss: 0.45111507\n","\n","Epoch: 28\n","Train Iteration 8800, Loss: 0.50107314\n","Train Iteration 8850, Loss: 0.38961686\n","Train Iteration 8900, Loss: 0.51822738\n","Train Iteration 8950, Loss: 0.63153148\n","Train Iteration 9000, Loss: 0.50874535\n","Train Iteration 9050, Loss: 0.43750984\n","Val Iteration 1800, Loss: 0.37287333\n","\n","Epoch: 29\n","Train Iteration 9100, Loss: 0.43187529\n","Train Iteration 9150, Loss: 0.60746287\n","Train Iteration 9200, Loss: 0.46791396\n","Train Iteration 9250, Loss: 0.46041888\n","Train Iteration 9300, Loss: 0.46457596\n","Train Iteration 9350, Loss: 0.47318082\n","Val Iteration 1850, Loss: 0.34806874\n","\n","Epoch: 30\n","Train Iteration 9400, Loss: 0.37260154\n","Train Iteration 9450, Loss: 0.50709396\n","Train Iteration 9500, Loss: 0.51741929\n","Train Iteration 9550, Loss: 0.35251186\n","Train Iteration 9600, Loss: 0.41513174\n","Train Iteration 9650, Loss: 0.47486122\n","Train Iteration 9700, Loss: 0.48847237\n","Val Iteration 1900, Loss: 0.43176372\n","Val Iteration 1950, Loss: 0.34010319\n","\n","Epoch: 31\n","Train Iteration 9750, Loss: 0.52100059\n","Train Iteration 9800, Loss: 0.51393329\n","Train Iteration 9850, Loss: 0.56847877\n","Train Iteration 9900, Loss: 0.49360563\n","Train Iteration 9950, Loss: 0.46085586\n","Train Iteration 10000, Loss: 0.52787432\n","Val Iteration 2000, Loss: 0.47937015\n","\n","Epoch: 32\n","Train Iteration 10050, Loss: 0.40645355\n","Train Iteration 10100, Loss: 0.46570054\n","Train Iteration 10150, Loss: 0.51343613\n","Train Iteration 10200, Loss: 0.41193262\n","Train Iteration 10250, Loss: 0.51569586\n","Train Iteration 10300, Loss: 0.46857717\n","Val Iteration 2050, Loss: 0.41318060\n","\n","Epoch: 33\n","Train Iteration 10350, Loss: 0.44970698\n","Train Iteration 10400, Loss: 0.49059450\n","Train Iteration 10450, Loss: 0.52489069\n","Train Iteration 10500, Loss: 0.64256181\n","Train Iteration 10550, Loss: 0.45327024\n","Train Iteration 10600, Loss: 0.45883264\n","Val Iteration 2100, Loss: 0.51350933\n","Average loss: 0.4925504928942344\n","Model and optimizer state saved to model_optim_state.npy\n"]}]},{"cell_type":"code","source":["# print(optimiser_np.state)"],"metadata":{"id":"AkvF5DIjpq5t","executionInfo":{"status":"ok","timestamp":1744307854397,"user_tz":-60,"elapsed":8,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["# print(optimiser_np.param_tuples)"],"metadata":{"id":"4UacOPuFe6QF","executionInfo":{"status":"ok","timestamp":1744373138211,"user_tz":-60,"elapsed":20,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#clear_auxiliary(model)"],"metadata":{"id":"SX5nvX0WwJX_","executionInfo":{"status":"ok","timestamp":1744354784825,"user_tz":-60,"elapsed":42,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#import gc\n","#gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cv6DppIDRwI8","executionInfo":{"status":"ok","timestamp":1744354785253,"user_tz":-60,"elapsed":13,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}},"outputId":"b05c3161-fcca-4be0-adcb-2e2823622eee"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["274"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["# ***3. Model Performance Evaluation (Task 3)***"],"metadata":{"id":"QQ4bBu-PQ3-g"}},{"cell_type":"code","source":["############################################################\n","#put your code for model performance evaluation here\n","def load_model_and_optimiser(model, optimiser, filename=\"model_optim_state.npy\"):\n","    \"\"\"\n","    Load pretrained model parameters and optimizer state from a file.\n","\n","    This function loads the state dictionary saved using 'save_model_and_optimiser', updates\n","    the model's parameters (in place) and sets the optimizer's state accordingly.\n","\n","    Args:\n","        model: The model instance whose parameters should be updated.\n","        optimiser: The instance of ADAM_np managing the model parameters.\n","        filename: The filename of the saved state (default is \"model_optim_state.npy\").\n","\n","    Raises:\n","        KeyError: If a parameter key from the model is not found in the saved state.\n","    \"\"\"\n","    import numpy as np\n","\n","    # Load the saved state dictionary with allow_pickle=True\n","    state = np.load(filename, allow_pickle=True).item()\n","    saved_model_state = state[\"model_state\"]\n","    saved_optimiser_state = state[\"optimizer_state\"]\n","\n","    # Refresh the mapping (the same order as used when saving is assumed)\n","    param_tuples = optimiser.get_pointers_to_param_and_grad(model)\n","\n","    # Update each parameter in the model using the saved state\n","    for (p, param_attr, mod, grad, grad_attr) in param_tuples:\n","        # Recreate the key used during saving\n","        key = f\"{mod.__class__.__name__}_{param_attr}_{id(p)}\"\n","        if key in saved_model_state:\n","            # In-place update of the parameter array\n","            p[...] = saved_model_state[key]\n","        else:\n","            # If key not found, it's likely there's a mismatch between model architectures\n","            raise KeyError(f\"Parameter key '{key}' not found in saved state. \"\n","                           \"Ensure that the model architecture and the optimizer pointers \"\n","                           \"match those used when saving.\")\n","\n","    # Update the optimizer state (this assumes the optimizer's internal state structure remains consistent)\n","    optimiser.state = saved_optimiser_state.copy()\n","\n","    print(f\"Loaded model and optimizer state from '{filename}'\")\n","\n","load_model_and_optimiser(model, optimiser_np)\n","all_labels = []\n","all_predictions = []\n","\n","for val_batch in val_batches:\n","    labels = val_batch[:, -1].reshape(-1, 1)\n","    features = np.expand_dims(val_batch[:, :-1], axis=-1)\n","    logits = model.forward(features)\n","\n","    probabilities = 1 / (1 + np.exp(-logits))\n","\n","    predictions = (probabilities >= 0.5).astype(int)\n","\n","    all_labels.append(labels)\n","    all_predictions.append(predictions)\n","\n","all_labels = np.concatenate(all_labels, axis=0)\n","all_predictions = np.concatenate(all_predictions, axis=0)\n","\n","TP = np.sum((all_predictions == 1) & (all_labels == 1))\n","FP = np.sum((all_predictions == 1) & (all_labels == 0))\n","TN = np.sum((all_predictions == 0) & (all_labels == 0))\n","FN = np.sum((all_predictions == 0) & (all_labels == 1))\n","\n","precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n","\n","recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n","\n","F1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n","\n","specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n","\n","balanced_accuracy = (recall + specificity) / 2\n","\n","# Print the results.\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {F1:.4f}\")\n","print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n","############################################################\n","\n","import matplotlib.pyplot as plt\n","# Assuming train_losses and val_losses are lists of loss values per epoch.\n","epochs = range(1, len(train_losses) + 1)\n","\n","plt.figure(figsize=(8, 5))\n","plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n","plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Train and Validation Loss Over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","test_features = np.expand_dims(nb15_dataset.test_set, axis=-1)\n","test_logits = model.forward(test_features)\n","test_probabilities = 1 / (1 + np.exp(-test_logits))\n","test_predictions = (test_probabilities >= 0.5).astype(int)\n","print(test_predictions)"],"metadata":{"id":"filj8Tb2Bav9","executionInfo":{"status":"ok","timestamp":1744382239423,"user_tz":-60,"elapsed":25949,"user":{"displayName":"Nam Tran","userId":"15778016803607933273"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7a35366a-8d49-4f52-cb3c-94a42481d771"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded model and optimizer state from 'model_optim_state.npy'\n","Precision: 0.9592\n","Recall: 0.6120\n","F1 Score: 0.7473\n","Balanced Accuracy: 0.7792\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]]\n"]}]},{"cell_type":"markdown","source":["# ***4. Performance Evaluation***"],"metadata":{"id":"1iCUL48FBwlQ"}},{"cell_type":"markdown","source":["**Please report the classification accuracy your model achieved on data samples in the testing set 1 below (in percentage)**"],"metadata":{"id":"hda1q3KOBM_f"}},{"cell_type":"markdown","source":["95.92%\n","\n"],"metadata":{"id":"ePqjGPnHmYWv"}},{"cell_type":"markdown","source":["**Please provide the predicted class labels of the data samples in the testing set 1 below (0 or 1)**"],"metadata":{"id":"MpMWHu9bCFSo"}},{"cell_type":"markdown","source":["| **Sample ID** |**Predicted Label** |\n","| --- | --- |\n","| 1 | 1 |\n","| 2 | 0 |\n","| 3 | 1 |\n","| 4 | 1 |\n","| 5 | 0  |\n","| 6 | 0  |\n","| 7 | 0  |\n","| 8 | 0  |\n","| 9 | 0  |\n","| 10 |0   |\n","| 11 |0   |\n","| 12 |0   |\n","| 13 |1   |\n","| 14 |1   |\n","| 15 |0   |\n","| 16 |0   |\n","| 17 |1   |\n","| 18 |1   |\n","| 19 |0   |\n","| 20 |0   |\n","| 21 |0   |\n","| 22 |1   |\n","| 23 |0   |\n","| 24 |0   |\n","| 25 |1   |"],"metadata":{"id":"R_8B_MxvCnf3"}}]}